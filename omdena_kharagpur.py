# -*- coding: utf-8 -*-
"""Omdena kharagpur.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16bTAG00K1Zbwn2i5HZPVbP63Da_bh6ur
"""

import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_excel('/content/drive/MyDrive/Sample Data _ Nov 14.xlsx')

df

df.head()

chars_hindi = [chr(c) for c in range(0x0900, 0x097f)]

df = df.astype(str)
df2 = df[df.Suggestion.map(lambda x: x.isascii())]

df2.describe()

df2.drop_duplicates(inplace = True, keep  = False)

df2.describe()

df2.dropna(how  = 'any' , inplace = True )

df2.info()

import string
string.punctuation

def punct(text):
    text_punc = []
    for char in text:
        if char  not in string.punctuation:
            text_punc.append(char)
        text_joined  = ''.join(text_punc)  
    return text_joined

df2['Suggestions'] = df2['Suggestion'].apply(punct)

df2

import nltk
nltk.download("stopwords")
from nltk.corpus import stopwords
stop_words = stopwords.words('english')

def preprocess(text):
    result = []
    for token in gensim.utils.simple_preprocess(text):
        if len(token) >=3 and token not in stop_words:
            result.append(token)
    return result

import gensim

df2['text'] = df2['Suggestions'].apply(preprocess)

df2

df2['Text'] = df2['text'].apply(lambda x: " ".join(x))

df2.drop(['Suggestion' , 'Suggestions' , 'text'] , axis = 1  , inplace = True)

df2.info()

